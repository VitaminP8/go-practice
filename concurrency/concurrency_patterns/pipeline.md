# Pipeline в Go: Организация потоковой обработки данных

**Pipeline** — это шаблон проектирования, который позволяет организовать потоковую обработку данных через последовательность этапов. Каждый этап представляет собой горутину, которая выполняет определенную операцию над данными и передает результат следующему этапу. Pipeline особенно полезен для обработки больших объемов данных или выполнения сложных задач, которые можно разделить на несколько этапов.

---

## Основные компоненты Pipeline

1. **Генератор (Generator)**:
    - Этап, который создает или получает данные и отправляет их в pipeline.

2. **Промежуточные этапы (Intermediate Stages)**:
    - Этапы, которые выполняют обработку данных (например, фильтрацию, преобразование) и передают результат следующему этапу.

3. **Завершающий этап (Consumer)**:
    - Этап, который принимает конечные данные и выполняет финальную обработку (например, сохранение или вывод).

---

## Пример Pipeline

```go
package main

import (
	"fmt"
	"time"
)

// Генератор: создает числа от 0 до n и отправляет их в канал
func generator(n int) <-chan int {
	out := make(chan int)
	go func() {
		for i := 0; i < n; i++ {
			out <- i
		}
		close(out)
	}()
	return out
}

// Промежуточный этап: умножает числа на 2
func multiply(in <-chan int) <-chan int {
	out := make(chan int)
	go func() {
		for num := range in {
			out <- num * 2
		}
		close(out)
	}()
	return out
}

// Промежуточный этап: добавляет 1 к каждому числу
func add(in <-chan int) <-chan int {
	out := make(chan int)
	go func() {
		for num := range in {
			out <- num + 1
		}
		close(out)
	}()
	return out
}

// Завершающий этап: выводит числа
func consumer(in <-chan int) {
	for num := range in {
		fmt.Println("Received:", num)
	}
}

func main() {
	// Создаем pipeline
	nums := generator(5)
	multiplied := multiply(nums)
	added := add(multiplied)

	// Запускаем завершающий этап
	consumer(added)
}
```

#### Вывод:
```
Received: 1
Received: 3
Received: 5
Received: 7
Received: 9
```

---

## Как это работает?

1. **Генератор**:
    - Создает числа от 0 до 4 и отправляет их в канал `nums`.

2. **Промежуточные этапы**:
    - `multiply` умножает каждое число на 2.
    - `add` добавляет 1 к каждому числу.

3. **Завершающий этап**:
    - `consumer` выводит конечные числа.

---

## Преимущества Pipeline

1. **Модульность**:
    - Каждый этап выполняет одну задачу, что делает код более модульным и поддерживаемым.

2. **Параллелизм**:
    - Каждый этап может выполняться в отдельной горутине, что позволяет эффективно использовать ресурсы процессора.

3. **Масштабируемость**:
    - Легко добавлять новые этапы или изменять существующие.

4. **Читаемость**:
    - Код становится более понятным, так как каждый этап выполняет одну конкретную задачу.


---

## Когда использовать Pipeline?

1. **Обработка больших объемов данных**:
    - Если данные можно разделить на этапы обработки.

2. **Параллельная обработка**:
    - Если этапы могут выполняться параллельно.

3. **Сложные задачи**:
    - Если задачу можно разделить на несколько простых этапов.

---

## Заключение

- **Pipeline** — это мощный шаблон для организации потоковой обработки данных.
- Используйте генераторы, промежуточные этапы и завершающие этапы для создания модульных и масштабируемых решений.
- Pipeline делает код более читаемым, модульным и эффективным в многопоточных сценариях.
